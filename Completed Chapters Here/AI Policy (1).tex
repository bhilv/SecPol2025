%Author: Jacob Stansbury
%Glossary for unique terms shown at the bottom.
\section* {Scope}
\paragraph \normalfont {This policy applies to all Honda employees and affiliates.}
\section* {Safeguards}
\paragraph {\textbf I. Introduction.} 
\paragraph \quad Honda is committed to full compliance with applicable laws related to the use of artificial intelligence in the countries in which Honda provides products and services. Additionally, Honda is committed to the ethical use of artificial intelligence. This Artificial Intelligence Use Policy (“AI Policy”) outlines Honda’s requirements with respect to the adoption of all forms of artificial intelligence at Honda. Such artificial intelligence adoption includes use for business efficiencies, operations, and inclusion in Honda’s products and services.
\paragraph \quad This Policy is applicable to all Honda directors, officers, board members, employees, contractors, representatives, affiliates, agents, and any person or entity performing services for or on behalf of Honda. The Ethics Board at Honda is responsible for the enforcement of this Policy.
\paragraph {\textbf II. Guiding Principles/}
\paragraph \quad The intent of this Policy is to provide general guidance on the use of AI at Honda so that Honda can leverage the use of AI as a tool while ensuring it continues to meet legal obligations and act in an ethical manner. The use of AI at Honda should never compromise Honda’s core values or introduce undue risk to the organization. Rather, the use of AI at Honda should be focused on improving business efficiencies and enhancing Honda’s ability to fulfill its mission.
\paragraph \quad It is important to remember that Honda is a global organization. Honda has entities and staff globally and provides its products and services to customers globally as well. Accordingly, this Policy provides overarching guidance based on global standards for the use of AI. Honda Representatives should be cognizant when using AI at Honda that they think about the global impact of their decision to use AI, as a similar use of AI in some countries may not be permitted in others.
\paragraph \quad This Policy is not intended to address every use of AI at Honda by a Honda Representative. There are certain business departments and functions at Honda that bear more considerations and potential risks. Before using any AI at Honda—whether for personal business tasks such as writing an email or more complex business processes such as analyzing datasets - you should consult with your manager and seek guidance. Also, please see Prohibited Uses in Section III below for situations in which AI may not be used at Honda, and High-Risk Use of AI Systems in Section V below for situations in which extreme caution is required when considering using AI.
\paragraph \quad In addition, there are certain Embedded AI Tools used in existing approved Honda software that do not require additional approval for use. For example, the use of Microsoft Word in which Microsoft Word has embedded an AI tool to check spelling or grammar. The use of Embedded AI Tools in approved software at Honda is permitted, provided those software tools are aligned with previous general business uses. New AI tools may be approved upon request to the AI committee.
\paragraph \quad A list of existing software tools with Embedded AI Tools that are approved at Honda:
\begin {itemize}
\item Microsoft 365.
\item Microsoft CoPilot inside of Honda systems.
\item TensorFlow and TensorFlow Lite.
\item Qualcomm Neural Network (QNN) software development kit (SDK).
\item NVIDIA DeepStream.
\item MicroAI AtomML.
\end {itemize}
\paragraph \quad When third-party software, services, or contractors are utilized or employed, any AI usage by software used by these parties or services must be noted and evaluated carefully. Contracted services that utilize AI technology should be considered in the same light as individual AI usage. Consult with the Legal Department about the inclusion of an AI-specific clause in any vendor or contractor agreements.
\paragraph \quad The following principles must be followed when considering using an AI system at Honda:
\begin {itemize}
\item The use of an AI system should primarily focus on completing departmental goals as directed by company leadership. Except for the use of an Embedded AI Tool in a software system approved for use at Honda, any use of a new AI System at Honda must be approved by the AI Committee.
\item Individuals using an AI system must have expertise in the subject matter for which the AI is used. AI is to be utilized as a tool and is not a substitute for expertise. For example, if using AI for coding, the individual deploying the AI must have expertise in coding.
\item All AI-generated content (writing, datasets, graphs, pictures, etc.) must be thoroughly reviewed by an individual with expertise to evaluate such content for accuracy as well as general proofing and editing. AI-generated content should be viewed as a starting point, not the finished product. Like any content at Honda, AI-generated content should conform to the look and feel of the Honda brand and voice.
\item Any use of an AI system must have clear objectives for the AI use as a tool and business-accepted data sets from which the AI draws. If the data sets that the AI is using are not accurate, then the information AI provides will not be accurate.
\item AI systems are trained on data that may contain inherent bias. Users of these systems are responsible for reviewing any AI-produced content for bias and correcting it as necessary.
\item Non-public Honda information must never be put into an open AI system.
\item Honda Representatives must document all AI systems they are utilizing and for what functions. Tracking the use of AI is not optional and is part of your job. Documentation of specific AI Embedded Tools in an approved existing software tool when using that tool as intended is not required. Discuss the process for tracking the use of AI systems with your department head.
\item The use of an AI system must be documented to capture institutional knowledge. For example, if AI is used to create code and included in a larger section of code, there must be documentation as to which code section is AI-derived and who reviewed it.
\item The use of an AI system must meet any terms of use or contractual limitations. Contractual restrictions or terms of use may restrict Honda’s use of an AI system that would otherwise be legally compliant and ethically sound. For example, an AI system’s terms of use may require the use of certain disclaimers in certain use situations or prohibit the use of the AI system to do certain tasks. Honda Representatives should have all terms or use or contracts for AI systems reviewed by the Legal Department to ensure compliance with contractual obligations in using an AI system.
\item of an AI system does not eliminate the need for other internal approvals required at Honda for the use of technology, such as a security review, privacy review, cost review and spend approval, legal review, human resources review, etc. An AI system should go through the same review and approval process as other software or services at Honda. You should also ensure within your business unit that your business leader is aware of the use of the AI system and has approved any use of the AI system, particularly for AI-generated content that will be relayed externally.
\end {itemize}
\paragraph{\textbf III. Prohibited Uses.}
\paragraph \quad There are certain uses of AI that are prohibited. Unless otherwise approved by the AI committee and respective department heads, Honda Representatives are prohibited from using AI systems for any of the following activities at any time: 
\begin {itemize}
\item Conducting political lobbying activities is prohibited. Lobbying is defined as any action aimed at influencing a Government, Government Official, or Government Entity for any reason.
\item Using AI systems to identify or categorize customers, candidates, employees, contractors, or other affiliated entities based on protected class status is prohibited.
\item Entering trade secrets, confidential information, or personal data about any individual into an open AI system.
\item Entering any sensitive information about an individual into any AI system. “Sensitive information” includes medical, financial, political affiliation, racial or ethnic origin, religious beliefs, gender, sexual orientation, disability status, or any other protected information relating to an individual.
\item Using an AI system to obtain legal advice, including, but not limited to, creating policies for internal use or to provide to third parties.
\item Creating intellectual property that Honda desires to register and/or holds significant value to the organization.
\end {itemize}
\paragraph{\textbf IV. Ethical Guidelines.}
\paragraph \quad Honda desires to act in an ethical manner when using AI. Accordingly, there may be uses of AI that are legally permissible but which do not meet ethical requirements. Any use of an AI system at Honda should conform to the following ethical guidelines:
\begin {itemize}
\item \textbf {Informed Consent:} Prior to inputting personal information into a closed AI system, ensure that you have obtained informed consent from the individual(s) whose personal information will be inputted.
\item \textbf {Integrity in Use:} All users of AI systems should be honest about how AI helped in getting the work done. Even if using an AI system approved by the AI Committee for an approved use, you should ensure your manager or the department requesting a task for which you are using an AI system is aware of your use of the AI system. Do not pass off AI-generated work as done by you solely. Additionally, you should ask permission if you desire to use an AI system tool to complete a task. For example, you should ask your manager and HR representative if you may use an AI system to assist in writing a performance evaluation.
\item \textbf {Appropriate Content:} Do not use company time or resources to generate content using an AI system that would be considered illegal, inappropriate, harmful to Honda’s brand or reputation, or disrespectful to others.
\item \textbf {Unauthorized Use:} Do not use company time or resources to generate content using an AI system for personal use without prior approval of the appropriate department leader.
\end {itemize}
\paragraph {\textbf V. High-Risk Use of AI Systems.}
\paragraph \quad There are certain uses of AI systems that are more high risk than others. As a global company, Honda is committed to complying with all AI legal requirements and guidance in the countries in which it operates. The European Union (“EU”) has classified the following potential uses of AI as posing a high risk to the health and safety or fundamental rights of natural persons. Therefore, there are several additional requirements for the use of AI systems in such cases. These requirements are listed in Appendix II, with certain functions highlighted below:
\begin{itemize}
\item \textbf{Personal Data in AI Systems:} AI should be used with extreme caution when inputting any personal data of an individual into a closed AI system (it is prohibited to put any personal data into an open AI system).
\item \textbf{Screening Job Candidates:} AI should be used with caution when screening any job applicants to ensure it does not adversely impact protected class members or introduce any bias. Equity and inclusion issues surrounding AI use in job screening are a potential source of litigation. 
\item \textbf{Personnel Decisions:} AI should be used with caution for any use related to making decisions on promotions, retention, or similar personnel such decisions. Extreme caution should be utilized to ensure that biases (including biases found in existing data sets) are avoided.
\item \textbf{Enrollment Decisions:} Extreme caution should be utilized if using AI in any manner related to evaluating potential candidates for admission into an academy, internship or apprenticeship program, or any other Honda program.
\end{itemize}
\paragraph {\textbf VI. General AI System Use Standards and Use Approval.}
\paragraph \quad Except for AI Embedded Tools in approved software, all uses of AI systems must be approved by the AI Committee prior to use to ensure such AI system use meets the following principles:
\begin{itemize}
\item \textbf{Lawful:} The use of AI systems must comply with all applicable laws and regulations, as well as any contractual obligations, limitations, or restrictions.
\item \textbf{Ethical:} The use of AI systems must adhere to ethical principles, be fair, and avoid bias.
\item \textbf {Transparency:} There must be clear objectives for the use of an AI system and documented oversight of such use, which is recorded and captured for institutional knowledge. Disclosures of the use of AI in any AI-assisted content generation must be made when required by law or contract, or when required by Honda.
\item \textbf {Necessity:} The use of AI systems must be for a valid business purpose to improve Honda’s business efficiencies and support the organization’s mission. The use of AI is not a substitute for human critical thinking or expertise and should not require Honda to incur an unnecessary expense without any true benefit.
\end{itemize}
\paragraph \quad Prior to submitting a request to the AI Committee for the use of an AI system, a requester should first obtain the approval of their manager. In addition, in evaluating whether to make a request, the requester should ensure that the AI system use, if approved, would conform with the guidelines in this Policy, prior to submitting said request. Requests for the use of an AI system should follow the SOP here [HYPOTHETICAL-LINK-TO-SOP].
\paragraph {\textbf VII. Training.}
\paragraph \quad All Honda Representatives who interact with AI systems must be trained on this Policy. Additionally, specific departments or functions at Honda may require more specific training on the use of AI systems for their department or function when more high-risk.
\paragraph {\textbf VIII. Reporting Non-Compliance.}
\paragraph \quad Honda directors, managers, employees, and agents aware of any conduct that may violate this Policy have a responsibility to report it. Individuals are encouraged to make reports through normal reporting relationships beginning with their manager. All reports of suspected misconduct or non-compliance will be investigated by the AI Committee, Legal Counsel, Human Resources, or other appropriate parties. Unless acting in bad faith, Honda employees will not be subject to reprisals for reporting potential violations.
\paragraph \quad If Honda determines that a Honda Representative has failed to comply with this Policy after an investigation concludes, then the Honda Representative will be subject to disciplinary action, up to and including termination.
\begin{center}
\section* {\textbf{\underline{Annex I}}\\ \large{\textbf{\underline{AI Techniques and Approaches}}}}
\end{center}
\paragraph \quad This annex outlines the approved artificial intelligence (AI) techniques and approaches authorized for use in Honda systems and infrastructure. It also identifies the tools through which these techniques are deployed, describes the primary use cases, and specifies associated constraints and security considerations. This annex will not be comprehensive, but rather a guideline for appropriate conduct. Ask your supervisor if you have questions about AI techniques and approaches.
\paragraph{\textbf I. Machine Learning Approaches.}
\paragraph {\textbf I.1 Supervised Learning.}
\paragraph \quad Supervised learning models are authorized for deployment in perception, classification, and predictive diagnostics applications.
\begin {itemize}
\item \textbf {Examples:} Convolutional Neural Networks (CNNs), Support Vector Machines (SVMs), Decision Trees, Long Short Term Memories (LSTMs).
\item \textbf {Tools Used:} TensorFlow/TensorFlowLite, Qualcomm Neural Network SDK, and NVIDIA DeepStream.
\item \textbf {Use Cases:} Driver assistance perception (vehicle, pedestrian, traffic light detection), predictive maintenance for rotating equipment, and in-cabin gesture recognition and personalization.
\end{itemize}
\paragraph {\textbf I.2 Unsupervised Learning.}
\paragraph \quad Unsupervised learning models are to be used primarily for anomaly detection and pattern recognition in cases where labeled data is scarce.
\begin{itemize}
\item \textbf {Examples:} Autoencoders, Clustering (K-Means, DBSCAN), Principal Component Analysis (PCA).
\item \textbf {Tools Used:} MicroAI AtomML and TensorFlow Lite.
\item \textbf {Use Cases:} Learning normal operational patterns of ECUs, motors, and sensors, and detecting abnormal behavior in factory robots or HVAC systems.
\end{itemize}
\paragraph {\textbf I.3 Reinforcement Learning.}
\paragraph \quad Reinforcement learning models are permitted for simulation and training purposes only; not allowed in direct control loops in production unless human oversight is guaranteed.
\begin{itemize}
\item \textbf {Examples:} Q-Learning, Deep Q-Networks (DQN), Proximal Policy Optimization (PPO).
\item \textbf {Tools Used:} TensorFlow.
\item \textbf {Use Cases:} Simulated driver behavior models and manufacturing flow optimization.
\item \textbf {Restrictions:} Reinforcement learning models may not autonomously update policies in production. Additionally, model deployment requires an audit of reward signal safety and risk tolerance.
\end{itemize}
\paragraph {\textbf I.4 Deep Learning.}
\paragraph \quad Deep learning techniques are authorized when used with approved frameworks and hardware platforms that support explainability or low-level model inspection.
\begin {itemize}
\item \textbf{Examples:} CNNs, recurrent neural networks (RNNs), Transformers, Attention Mechanisms.
\item \textbf {Tools Used:} TensorFlow/TensorFlow Lite and ONNX Runtime via QNN SDK or DeepStream.
\item \textbf {Use Cases:} In-vehicle visual perception and speech interfaces and lane following and environmental awareness in advanced driver assistance systems (ADAS).
\end{itemize}
\paragraph {\textbf II. Logic and Knowledge-Based Approaches.}
\paragraph \quad Knowledge-based and symbolic reasoning systems are approved in scenarios requiring rule-based decisions, traceability, and legal compliance.
\begin {itemize}
\item \textbf{Examples:} Knowledge graphs, deductive engines, inference rules, and expert systems.
\item \textbf {Tools Used:} Microsoft Copilot (when deployed with restricted access to internal documentation systems) and embedded rule engines within AtomML environments.
\item \textbf {Use Cases:} Repair recommendation systems and internal support automation using CoPilot in code review or documentation workflows.
\end{itemize}
\paragraph {\textbf III. Statistical and Probabilistic Methods.}
\paragraph \quad Statistical inference and probabilistic modeling techniques are permitted for decision support and analytical modeling. These approaches form the foundation of many AI model components.
\begin {itemize}
\item \textbf{Examples:} Bayesian Networks, Gaussian Mixture Models, Kalman Filters, Markov Chains.
\item \textbf {Tools Used:} TensorFlow (Bayesian layers) for probabilistic neural networks and MicroAI AtomML for running lightweight, statistical model-based anomaly detection on-device.
\item \textbf {Use Cases:} Sensor fusion in ADAS and forecasting fuel efficiency or component wear.
\end{itemize}
\paragraph {\textbf IV. Tool-Specific Constraints and Conditions.}
\begin{itemize}
\item \textbf{Microsoft CoPilot:} Approved only in isolated developer environments. Output must not be used in production decision systems without validation.
\item \textbf{TensorFlow/TensorFlow Lite:} Permitted for training and edge inference. Inference models must be quantized, validated, and signed before deployment.
\item \textbf{Qualcomm Neural Network SDK:} Permitted only for inference on validated Snapdragon-based hardware. Backend layer assignments must be logged.
\item \textbf{NVIDIA DeepStream:} Approved for video-based inference systems. Pipelines must be locked from runtime modification and only use validated ONNX or TensorRT models.
\item \textbf{MicroAI AtomML:}  Permitted for both training and inference at the edge. Runtime adaptation must be sandboxed, with thresholds and feedback loops tuned to prevent drift or overfitting.
\end{itemize}
\begin{center}
\section* {\textbf{\underline{Annex II}}\\ \large{\textbf{\underline{EU High-Risk System Requirements}}}}
\end{center}
\paragraph \quad Requirements should apply to high-risk AI systems as regards the quality of data sets used, technical documentation and record-keeping, transparency, the provision of information to users, human oversight, robustness, accuracy, and cybersecurity. Those requirements are necessary to effectively mitigate the risks for health, safety, and fundamental rights, as applicable in the light of the intended purpose of the system, and no other less trade-restrictive measures are available, thus avoiding unjustified restrictions to trade.
\paragraph \quad High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely, and it does not become the source of discrimination prohibited by Union law. High-quality training, validation, and testing data sets require the implementation of appropriate data governance and management practices. Training, validation, and testing data sets should be relevant, representative, free of errors, and complete in view of the system's intended purpose. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. Training, validation, and testing data sets should consider, to the extent required in the light of their intended purpose, the features, characteristics, or elements that are particular to the specific geographical, behavioral, or functional setting or context within which the AI system is intended to be used. To protect the rights of others from the discrimination that might result from the bias in AI systems, the providers should be able to process also special categories of personal data, as a matter of substantial public interest, to ensure the bias monitoring, detection, and correction in relation to high-risk AI systems.
\paragraph \quad For the development of high-risk AI systems, certain actors, such as providers, notified bodies, and other relevant entities, such as digital innovation hubs, testing experimentation facilities, and researchers, should be able to access and use high-quality datasets within their respective fields of activities which are related to this Regulation. European common data spaces established by the Commission and the facilitation of data sharing between businesses and with the government in the public interest will be instrumental in providing trustful, accountable, and non-discriminatory access to high-quality data for the training, validation, and testing of AI systems. For example, in health, the European health data space will facilitate non-discriminatory access to health data and the training of artificial intelligence algorithms on those datasets, in a privacy-preserving, secure, timely, transparent, and trustworthy manner, and with appropriate institutional governance. Relevant competent authorities, including sectoral ones, providing, or supporting the access to data may also support the provision of high-quality data for the training, validation and testing of AI systems.
\paragraph \quad Having information on how high-risk AI systems have been developed and how they perform throughout their lifecycle is essential to verify compliance with the requirements under this Regulation. This requires keeping records and technical documentation, containing information necessary to assess the AI system's compliance with the relevant requirements. Such information should include the typical characteristics, capabilities and limitations of the system, algorithms, data, training, testing, and validation processes used, as well as documentation on the relevant risk management system. The technical documentation should be kept up to date.
\paragraph \quad To address the opacity that may make certain AI systems incomprehensible or too complex for natural persons, a certain degree of transparency should be required for high-risk AI systems. Users should be able to interpret the system output and use it appropriately. High-risk AI systems should, therefore, be accompanied by relevant documentation and instructions of use and include concise and clear information, including in relation to risks to fundamental rights and discrimination, where appropriate.
\paragraph \quad High-risk AI systems should be designed and developed in such a way that natural persons can oversee their functioning. For this purpose, appropriate human oversight measures should be identified by the provider of the system before it is placed on the market or put into service. Where appropriate, such measures should guarantee that the system is subject to in-built operational constraints that cannot be overridden by the system itself and is responsive to the human operator, and that the natural persons to whom human oversight has been assigned have the necessary competence, training, and authority to carry out that role.
\paragraph \quad High-risk AI systems should perform consistently throughout their lifecycle and meet an appropriate level of accuracy, robustness, and cybersecurity in accordance with the acknowledged state of the art. The level of accuracy and accuracy metrics should be communicated to the users.
\paragraph \quad Technical robustness is a key requirement for high-risk AI systems. They should be resilient against risks connected to the limitations of the system (e.g., errors, faults, inconsistencies, unexpected situations) as well as against malicious actions that may compromise the security of the AI system and result in harmful or otherwise undesirable behavior. Failure to protect against these risks could lead to safety impacts or negatively affect fundamental rights, for example, due to erroneous decisions or wrong or biased outputs generated by the AI system.
\paragraph \quad Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behavior, and performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can leverage AI-specific assets, such as training data sets (e.g., data poisoning) or trained models (e.g., adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, suitable measures should therefore be taken by the providers of high-risk AI systems, also considering as appropriate the underlying ICT infrastructure.
\paragraph \normalfont{Source: EU Artificial Intelligence Act, para. 43-51}
\begin{center}
\section* {\textbf{\underline{Annex III}}\\ \large{\textbf{\underline{Potentially Applicable EU High-Risk System Types}}}}
\end{center}
\begin{itemize}
\item ‘Real-time’ and ‘post’ remote biometric identification systems. Both types should be subject to specific requirements on logging capabilities and human oversight.
\item AI systems used in education or vocational training, notably for determining access or assigning persons to educational and vocational training institutions or to evaluate persons on tests as part of or as a precondition for their education.
\item AI systems used in employment, workers management, and access to self-employment, notably for the recruitment and selection of persons, for making decisions on promotion and termination, and for task allocation, monitoring, or evaluation of persons in work-related contractual relationships.
\item Access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. AI systems are used to evaluate the credit score or creditworthiness of natural persons.
\end{itemize}
\paragraph \normalfont{Source: EU Artificial Intelligence Act, para. 33-37}
\section* {\textbf{\underline{GLOSSARY - CHECK COMMENTS.}}} %annexes not included
% \newglossaryentry{Embedded_AI_Tools}{name={ Embedded AI Tools }, description {AI tools embedded in existing software tools approved and used at Honda and which do not require approval for use from the AI Committee.}}
% \newglossaryentry{Closed_AI_System}{name={ Closed AI System }, description {An AI system where the input provided by one user is used to train the AI model. Input data from the user is isolated from other users, and the data is considered more secure.}}
% \newglossaryentry{Government}{name={ Government }, description {The government of a country or subdivision thereof.}}
% \newglossaryentry{Government_Entity}{name={ Government Entity }, description {Any entity controlled by a government in whole or part. This includes Government-owned or controlled (whether whole or partial ownership or control) commercial enterprises, institutions, agencies, departments, instrumentalities, and other public entities, including research institutions and universities.}}
% \newglossaryentry{Government_Official}{name={ Government Official }, description {Any officer or employee of a Government Entity, an official of a political party, a candidate for political office, officers and employees of non-governmental international organizations, and any person with responsibility to allocate or influence expenditures of Government funds. This includes data scientists and researchers who are employed by a government or a Government Entity. Employees at government organizations are considered Government Officials regardless of title or position.}}
% \newglossaryentry{Non-public_Honda_Data}{name={ Non-public Honda Data }, description {Any information that, if disclosed, could violate the privacy of individuals, government regulations or statutes, could jeopardize the financial state of Honda, could injure its reputation, or could reduce its competitive advantage. 
%\newglossaryentry{Open_AI_System} {name={ Open AI System }, description {Open AI System: An AI system where the input provided by all users is used to train the AI model. Input data from all users is not private and may be revealed to other users.}}
% \newglossaryentry{Personal_Information}{name={ Personal Information }, description {Information that identifies, relates to, describes, is capable of being associated with, or could reasonably be linked, directly or indirectly, with a particular person or household.}}
%\newglossaryentry{Honda_Representatives}{name={ Honda Representatives }, description {All Honda directors, officers, board members, employees, contractors, representatives, resellers and sub-resellers, distributors and sub-distributors, affiliates, agents, and any person or entity performing services for or on behalf of Honda.}}